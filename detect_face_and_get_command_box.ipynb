{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "# patch tf1 into `utils.ops`\n",
    "utils_ops.tf = tf.compat.v1\n",
    "\n",
    "# Patch the location of gfile\n",
    "tf.gfile = tf.io.gfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    model = tf.saved_model.load(model_path)\n",
    "    model = model.signatures['serving_default']\n",
    "\n",
    "    return model\n",
    "\n",
    "# Load face detector\n",
    "detection_model_path = './models/face_tf_trt_FP16'\n",
    "\n",
    "# Load hand sign recognizer\n",
    "hand_sign_classes = [\"0_front\", \"1_back\", \"1_front\", \"2_back\", \"2_front\", \"5_front\", \"ILU\"]\n",
    "# classification_model_path = './models/hand_sign_tf_trt_FP16'\n",
    "# classification_model_path = './models/hand_sign_saved_model'\n",
    "classification_model_path = './models/hand_sign.h5'\n",
    "\n",
    "face_detector = load_model(detection_model_path)\n",
    "# hand_sign_recongizer = load_model(classification_model_path)\n",
    "hand_sign_recongizer = tf.keras.models.load_model(classification_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_for_single_image(model, image):\n",
    "    image = np.asarray(image)\n",
    "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "    input_tensor = tf.convert_to_tensor(image)\n",
    "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "    input_tensor = input_tensor[tf.newaxis,...]\n",
    "\n",
    "    # Run inference\n",
    "    output_dict = model(input_tensor)\n",
    "\n",
    "    # All outputs are batches tensors.\n",
    "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "    # We're only interested in the first num_detections.\n",
    "    num_detections = int(output_dict.pop('num_detections'))\n",
    "    output_dict = {key:value[0, :num_detections].numpy() \n",
    "                    for key,value in output_dict.items()}\n",
    "    output_dict['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
    "\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_absolute(im_height, im_width, box):\n",
    "    box_abs = []\n",
    "    box_abs = [box[0] * im_height,\n",
    "               box[1] * im_width,\n",
    "               box[2] * im_height,\n",
    "               box[3] * im_width]\n",
    "    \n",
    "    return box_abs\n",
    "\n",
    "\n",
    "def convert_to_predict_box(face_box_to_track_ids_map):\n",
    "    predict_box_to_track_ids_map = {}\n",
    "    for face_box, track_id in face_box_to_track_ids_map.items():\n",
    "        y_min = face_box[0]\n",
    "        x_min = face_box[1]\n",
    "        y_max = face_box[2]\n",
    "        x_max = face_box[3]\n",
    "\n",
    "        predict_box = [y_min, x_min-(x_max-x_min), y_max, x_min]\n",
    "\n",
    "        x_offset = (predict_box[3]-predict_box[1])*0.5\n",
    "        y_offset = (predict_box[2]-predict_box[0])*0.5\n",
    "\n",
    "        predict_box[0] -= 0.5*y_offset\n",
    "        predict_box[1] -= 2.5*x_offset\n",
    "        predict_box[2] += 2*y_offset\n",
    "\n",
    "        for i in range(len(predict_box)):\n",
    "            if(predict_box[i] <= 0.0):\n",
    "                predict_box[i] = 0.0\n",
    "            elif(predict_box[i] >= 1.0):\n",
    "                predict_box[i] = 1.0\n",
    "        \n",
    "        predict_box_to_track_ids_map[tuple(predict_box)] = track_id\n",
    "        \n",
    "    return predict_box_to_track_ids_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow Saved Model style\n",
    "# def predict_hand_sign(image):\n",
    "#     image = cv2.resize(image, (150, 150))\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "#     input_img = np.expand_dims(image, axis=0)    \n",
    "#     input_img = input_img.astype(np.float32) / 255.\n",
    "#     input_tensor = tf.constant(input_img)\n",
    "    \n",
    "#     result = hand_sign_recongizer(input_tensor)\n",
    "#     preds = result['dense_1'].numpy()\n",
    "#     return preds\n",
    "\n",
    "\n",
    "# Keras model(*.h5) style\n",
    "def predict_hand_sign(image):\n",
    "    image = cv2.resize(image, (150, 150))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    input_img = np.expand_dims(image, axis=0)    \n",
    "    input_img = input_img.astype(np.float32) / 255.\n",
    "    \n",
    "    preds = hand_sign_recongizer(input_img)\n",
    "    return preds\n",
    "\n",
    "\n",
    "def visualize_box(bg_image, box, display_str, color):\n",
    "    ymin, xmin, ymax, xmax = box\n",
    "    vis_util.draw_bounding_box_on_image_array(bg_image,\n",
    "                                              ymin,\n",
    "                                              xmin,\n",
    "                                              ymax,\n",
    "                                              xmax,\n",
    "                                              color=color,\n",
    "                                              thickness=4,\n",
    "                                              display_str_list=display_str,\n",
    "                                              use_normalized_coordinates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face_and_get_command_box(image,\n",
    "                                    boxes,\n",
    "                                    classes,\n",
    "                                    scores,\n",
    "                                    track_ids,\n",
    "                                    use_normalized_coordinates=False,\n",
    "                                    max_boxes_to_draw=20,\n",
    "                                    min_score_thresh=.5,\n",
    "                                    line_thickness=4):\n",
    "\n",
    "    # 1. Detect face\n",
    "    face_box_to_track_ids_map = {}\n",
    "    if not max_boxes_to_draw:\n",
    "        max_boxes_to_draw = boxes.shape[0]\n",
    "    for i in range(min(max_boxes_to_draw, boxes.shape[0])):\n",
    "        if scores is None or scores[i] > min_score_thresh:\n",
    "            box = tuple(boxes[i].tolist())\n",
    "            face_box_to_track_ids_map[box] = track_ids[i]\n",
    "\n",
    "    \n",
    "    # 2. Find command sign\n",
    "    command_box_to_track_ids_map = {}\n",
    "    \n",
    "    if len(face_box_to_track_ids_map) != 0:\n",
    "        im_height, im_width, _ = image.shape\n",
    "        box_to_display_str_map = collections.defaultdict(list)\n",
    "        predict_box_to_track_ids_map = convert_to_predict_box(face_box_to_track_ids_map)\n",
    "        \n",
    "        for predict_box, track_id in predict_box_to_track_ids_map.items():\n",
    "            predict_box_abs = convert_to_absolute(im_height, im_width, list(predict_box))\n",
    "            predict_box_img = image[int(predict_box_abs[0]):int(predict_box_abs[2]),\n",
    "                                    int(predict_box_abs[1]):int(predict_box_abs[3])]\n",
    "\n",
    "            # invalid box check\n",
    "            if predict_box_img.size == 0:\n",
    "                continue\n",
    "\n",
    "            preds = predict_hand_sign(np.array(predict_box_img))\n",
    "            if np.amax(preds[0]) > 0.85:\n",
    "                # command sign\n",
    "                if np.argmax(preds[0]) == 5:\n",
    "                    display_str = 'command_box'\n",
    "                    display_str = '{}: ID {}'.format(display_str, track_id)\n",
    "                    box_to_display_str_map[predict_box].append(display_str)\n",
    "                    command_box_to_track_ids_map[tuple(predict_box)] = track_id\n",
    "    \n",
    "        # 3. Visualize command box\n",
    "        for box, display_str in box_to_display_str_map.items():\n",
    "            visualize_box(image, box, display_str, 'LightGrey')\n",
    "            \n",
    "    return command_box_to_track_ids_map\n",
    "\n",
    "\n",
    "def predict_hand_sign_and_get_command(image, command_box_to_track_ids_map):\n",
    "    im_height, im_width, _ = image.shape\n",
    "    \n",
    "    for command_box, track_id in command_box_to_track_ids_map.items():\n",
    "        command_box_abs = convert_to_absolute(im_height, im_width, list(command_box))\n",
    "        command_box_img = image[int(command_box_abs[0]):int(command_box_abs[2]),\n",
    "                                int(command_box_abs[1]):int(command_box_abs[3])]\n",
    "\n",
    "        # invalid box check\n",
    "        if command_box_img.size == 0:\n",
    "            continue\n",
    "        \n",
    "        preds = predict_hand_sign(np.array(command_box_img))\n",
    "            \n",
    "        if np.amax(preds[0]) >= 0.97:\n",
    "            class_idx = np.argmax(preds[0])\n",
    "            # command sign\n",
    "            if class_idx != 5:\n",
    "                display_str = hand_sign_classes[class_idx]\n",
    "                display_str = '{}: ID {}'.format(display_str, track_id)\n",
    "                visualize_box(image, command_box, display_str, 'Green')\n",
    "                \n",
    "                return class_idx\n",
    "            \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current FPS :  30.0\n",
      "0_front\n",
      "1_front\n",
      "0_front\n",
      "0_front\n"
     ]
    }
   ],
   "source": [
    "def most_frequent(l):\n",
    "    if len(l) != 0:\n",
    "        return max(set(l), key = l.count) \n",
    "    \n",
    "\n",
    "# Frame's Width, Height\n",
    "FRAME_WIDTH = 640\n",
    "FRAME_HEIGHT = 480\n",
    "\n",
    "# Initialize webcam feed\n",
    "video = cv2.VideoCapture(0)\n",
    "# video = cv2.VideoCapture('/home/young/Desktop/test/5.mp4')\n",
    "if not video.isOpened():\n",
    "    print(\"Cannot open video\")\n",
    "    exit()\n",
    "    \n",
    "video.set(cv2.CAP_PROP_FRAME_WIDTH, FRAME_WIDTH)\n",
    "video.set(cv2.CAP_PROP_FRAME_HEIGHT, FRAME_HEIGHT)   \n",
    "print('Current FPS : ', video.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "max_detection = 10\n",
    "person_ids = list(range(max_detection))\n",
    "prev = {}\n",
    "\n",
    "while(True):\n",
    "    ret, frame = video.read()\n",
    "    if ret is False:\n",
    "        print(\"Can't receive frame\")\n",
    "        break\n",
    "        \n",
    "    output_dict = run_inference_for_single_image(face_detector, cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    command_box_to_track_ids_map = detect_face_and_get_command_box(image=frame,\n",
    "                                                                   boxes=output_dict['detection_boxes'],\n",
    "                                                                   classes=output_dict['detection_classes'],\n",
    "                                                                   scores=output_dict['detection_scores'],\n",
    "                                                                   track_ids = person_ids,\n",
    "                                                                   use_normalized_coordinates=True,\n",
    "                                                                   max_boxes_to_draw = max_detection,\n",
    "                                                                   line_thickness=8)\n",
    "        \n",
    "    cv2.imshow('video', frame)\n",
    "    # Press 'esc' to quit\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "    \n",
    "    if len(command_box_to_track_ids_map) < len(prev):\n",
    "        start_time = time.time()\n",
    "        command_list = []\n",
    "        while(True):\n",
    "            ret, frame = video.read()\n",
    "            if ret is False:\n",
    "                print(\"Can't receive frame\")\n",
    "                break\n",
    "                \n",
    "            command = predict_hand_sign_and_get_command(frame, prev)\n",
    "\n",
    "            if command is not None:\n",
    "                command_list.append(command)\n",
    "                \n",
    "            cv2.imshow('video', frame)\n",
    "            # Press 'esc' to quit\n",
    "            if cv2.waitKey(1) == 27:\n",
    "                break\n",
    "            \n",
    "            if time.time()-start_time >= 2.0:\n",
    "                print(hand_sign_classes[int(most_frequent(command_list))])\n",
    "                break\n",
    "                \n",
    "    prev = command_box_to_track_ids_map\n",
    "\n",
    "# Clean up\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
